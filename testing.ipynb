{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install langgraph\n",
    "# %pip install langchain\n",
    "# %pip install langchain-openai\n",
    "# %pip install langchain-cohere\n",
    "# %pip install pinecone-client\n",
    "# %pip install langchain-pinecone\n",
    "# %pip install python-dotenv\n",
    "# %pip install pandas \n",
    "# %pip install langchain_core\n",
    "# %pip install langgraph-checkpoint-sqlite\n",
    "# %pip install sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage\n",
    "from langchain_core.tools import tool\n",
    "from langchain_cohere import ChatCohere\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from typing import TypedDict, Annotated\n",
    "from dotenv import load_dotenv\n",
    "from pinecone import Pinecone\n",
    "import operator\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import uuid\n",
    "from contextlib import ExitStack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create an agent with these goals:\n",
    "## 1. ingest user's idea\n",
    "## 2. search the web for information on the largest companies in the space of their idea\n",
    "## 3. return the top companies\n",
    "## 4. \n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# model = ChatCohere(model=\"command-r-plus\")\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "search_tool = TavilySearchResults(max_results=4) \n",
    "\n",
    "stack = ExitStack()\n",
    "memory = stack.enter_context(SqliteSaver.from_conn_string(\":memory:\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResearcherState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], operator.add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "research_prompt = \"\"\"You an expert in market analysis. \\\n",
    "You are given a user's idea and you must gather research on the largest companies related to that idea or domain. \\\n",
    "\n",
    "If you do not have the information to accurately describe the major companies in the space or related to the idea, you must perform a search to find the most relevant information. \\\n",
    "Return the research gathered on the companies.\n",
    "\n",
    "Examples:\n",
    "Input: \n",
    "User query: \"Vehicle rentals in toronto, but renting out your own car\" \\\n",
    "Researcher context: \"\" \\\n",
    "Output: \n",
    "\"A search is needed because I do not have any information yet regarding this idea. The search query is: 'short-termvehicle rental apps toronto'\"\n",
    "\n",
    "Input: \n",
    "User query: \"Vehicle rentals in Toronto, but renting out your own car\" \\\n",
    "Researcher context: \"Lyft: does not require the user to own a car. \\\n",
    "Zipcar: allows users to rent cars by the day or week. \\\n",
    "Turo: allows users to rent out their own cars to others. \\\n",
    "Communato: has vehicles allocated over the city which users can access at any time.\" \\\n",
    "Output: \n",
    "\"In the space of vehicle rentals in toronto, but renting out your own car, the major companies are Lyft, Zipcar, and Turo. \\\n",
    "Lyft is a ridesharing service that does not require the user to own a car. \\\n",
    "Zipcar is a car-sharing service that allows users to rent cars by the day or week. \\\n",
    "Turo is a peer-to-peer car-sharing platform that allows individuals to rent out their own cars to others. \\\n",
    "Communato is a company that has vehicles allocated over the city which users can access at any time.\"\n",
    "\"\"\"\n",
    "\n",
    "comparison_prompt = \"\"\"You are an expert in identifying the unique selling points of companies. \\\n",
    "You are given a user's idea and you must compare it with the unique selling points of the top companies in the space. \\\n",
    "\n",
    "Return the user's idea and the unique selling points of the top companies in the space, as well as whether the user's idea is actually unique compared to the other companies.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResearchAgent:\n",
    "    def __init__(self, model, tools, checkpointer, research_prompt=\"\", comparison_prompt=\"\"):\n",
    "        self.research_prompt = research_prompt\n",
    "        self.comparison_prompt = comparison_prompt\n",
    "        graph = StateGraph(ResearcherState)\n",
    "        graph.add_node(\"researcher\", self.researcher)\n",
    "        graph.add_node(\"tool_usage\", self.take_action)\n",
    "        graph.add_node(\"comparison\", self.comparison)\n",
    "        graph.add_conditional_edges(\"researcher\", self.exists_action, {True: \"tool_usage\", False: \"comparison\"})\n",
    "        graph.add_edge(\"tool_usage\", \"researcher\")\n",
    "        graph.add_edge(\"comparison\", END)\n",
    "        graph.set_entry_point(\"researcher\")\n",
    "        self.graph = graph.compile(checkpointer=checkpointer)\n",
    "        self.tools = {t.name: t for t in tools}\n",
    "        self.base_model = model\n",
    "        self.tool_model = model.bind_tools(tools)\n",
    "\n",
    "    def researcher(self, state: ResearcherState):\n",
    "        messages = state['messages']\n",
    "        if self.research_prompt:\n",
    "            messages = [SystemMessage(content=self.research_prompt)] + messages\n",
    "        message = self.tool_model.invoke(messages)\n",
    "        return {'messages': [message]}\n",
    "\n",
    "    def exists_action(self, state: ResearcherState):\n",
    "        result = state['messages'][-1]\n",
    "        return len(result.tool_calls) > 0\n",
    "\n",
    "    def take_action(self, state: ResearcherState):\n",
    "        tool_calls = state['messages'][-1].tool_calls\n",
    "        results = []\n",
    "        for t in tool_calls:\n",
    "            print(f\"Calling: {t}\")\n",
    "            result = self.tools[t['name']].invoke(t['args'])\n",
    "            results.append(ToolMessage(tool_call_id=t['id'], name=t['name'], content=str(result)))\n",
    "        print(\"Back to the model!\")\n",
    "        return {'messages': results}\n",
    "    \n",
    "    def comparison(self, state: ResearcherState):\n",
    "        messages = state['messages']\n",
    "        if self.comparison_prompt:\n",
    "            messages = [SystemMessage(content=self.comparison_prompt)] + messages\n",
    "        message = self.base_model.invoke(messages)\n",
    "        return {'messages': [message]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = [HumanMessage(content=\"Vehicle rentals in toronto, but renting out your own car?\")]\n",
    "user_uuid = str(uuid.uuid4())\n",
    "print(user_uuid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(user_input[-1].content)\n",
    "\n",
    "researcher_agent = ResearchAgent(model, [search_tool], research_prompt=research_prompt, comparison_prompt=comparison_prompt, checkpointer=memory)\n",
    "thread = {\"configurable\": {\"thread_id\": user_uuid}}\n",
    "\n",
    "attempts = 0\n",
    "while attempts < 3:\n",
    "    try:\n",
    "        # results = router(curator_agent, artifact_agent, thread, user_input)\n",
    "        for event in researcher_agent.graph.stream({\"messages\": user_input}, thread):\n",
    "            for v in event.values():\n",
    "                print(v['messages'])\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print('Error: ', e)\n",
    "        thread = {\"configurable\": {\"thread_id\": str(uuid.uuid4())}}\n",
    "        attempts += 1\n",
    "        if attempts == 3:\n",
    "            print(\"Failed to run the graph 3 times\")\n",
    "            break\n",
    "                \n",
    "# print(results['last_agent'])\n",
    "# last_agent = results['last_agent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
